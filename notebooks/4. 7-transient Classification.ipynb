{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "RESULTS_PATH = '../results/'\n",
    "FEATURES_PATH = DATA_PATH + 'features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Transient Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'transient_catalog.pickle'\n",
    "indir = DATA_PATH; filepath = indir + filename\n",
    "df_cat = pd.read_pickle(filepath)\n",
    "# Rename columns to match light curves\n",
    "df_cat = df_cat.rename(columns={'TransientID': 'ID', 'Classification': 'class'})\n",
    "print(df_cat.ID.unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Feature Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use catalogue of transients with min observations\n",
    "min_obs = 5\n",
    "num_features = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loead transient features\n",
    "indir = FEATURES_PATH\n",
    "filename = 'transient_features_{}obs_{}feats.pickle'.format(min_obs, num_features)  \n",
    "inpath = indir + filename\n",
    "df_feat_tran = pd.read_pickle(inpath)\n",
    "df_feat_tran.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add classs label to transient objects\n",
    "df_feat_tran = df_feat_tran.merge(df_cat , how='inner')\n",
    "# Remove ambiguous classes\n",
    "top_classes = ['SN', 'CV', 'AGN', 'HPM', 'Blazar', 'Flare']\n",
    "in_top = lambda row: ('Other' if row['class'] not in top_classes else row['class'])\n",
    "df_feat_tran['class'] = df_feat_tran.apply( in_top , axis=1)\n",
    "# Remove IDs\n",
    "df = df_feat_tran.drop(['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain X and y\n",
    "X = df.drop(['class'], axis=1).as_matrix()\n",
    "y = df['class'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of objects per class\n",
    "dict(zip(*np.unique(y, return_counts=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total number of objects\n",
    "np.sum(np.unique(y, return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in Test & Train Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define classfication routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_model(model, params, X_train, y_train, X_test, y_test):\n",
    "    # Precision decimal places\n",
    "    digits = 4\n",
    "    # Train & cross-validate\n",
    "    grid_search = GridSearchCV(model, tuned_parameters, cv=StratifiedKFold(2))\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    # Train new model with all train data\n",
    "    clf = grid_search.best_estimator_\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict test inputs with new model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Create results using real and predicted labels of test data \n",
    "    results_str = results_string(y_test, y_pred, grid_search, digits=digits)\n",
    "    print(results_str)\n",
    "    # Save results\n",
    "    task = 'binary'\n",
    "    model_name = model.__class__.__name__\n",
    "    filename = '{}_{}obs_{}feat_{}'.format(task, min_obs, num_features, model_name)\n",
    "    with open(RESULTS_PATH + filename + '.txt', 'w+') as f: f.write(results_str)\n",
    "        \n",
    "    return clf\n",
    "\n",
    "def results_string(y_true, y_pred, grid_search, digits):\n",
    "    float_param = '{0:.' + str(digits) + 'f}'\n",
    "    results = str()\n",
    "    results += 'Best Params: {}\\n'.format(grid_search.best_params_)\n",
    "    results += ('Validation Accuracy: ' + float_param + '\\n').format(grid_search.best_score_)\n",
    "    results += ('Test Accuracy: ' + float_param + '\\n').format(accuracy_score(y_test, y_pred))\n",
    "    results += 'Report:\\n {}'.format(classification_report(y_test, y_pred, digits=digits))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify using SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma':[1e-1, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'C': [1, 10, 100, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(random_state=0, class_weight='balanced')\n",
    "clf1 = train_validate_test_model(model, tuned_parameters, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify using RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = { \n",
    "    'n_estimators': [200, 700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=0, class_weight='balanced')\n",
    "clf2 = train_validate_test_model(model, tuned_parameters, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {\n",
    "    'learning_rate': ['constant', \"adaptive\"],\n",
    "    'hidden_layer_sizes': [(100), (100,100)],\n",
    "    'alpha': [1e-2, 1e-3],\n",
    "    'activation': [\"logistic\", \"relu\", \"tanh\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MLPClassifier(random_state=0)\n",
    "clf3 = train_validate_test_model(model, tuned_parameters, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
