{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "LIGHTCURVES_PATH = DATA_PATH + 'lightcurves/'\n",
    "FEATURES_PATH = DATA_PATH + 'features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import inputs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import measurements, extract\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import transient lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'transient_lightcurves.pickle'\n",
    "indir = LIGHTCURVES_PATH; filepath = indir + filename\n",
    "df_tra = pd.read_pickle(filepath)\n",
    "df_tra['ID'] = df_tra.TransientID\n",
    "df_tra = df_tra.drop('TransientID', axis=1)\n",
    "df_tra.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter transient lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows of blended observations\n",
    "df_tra = df_tra.drop_duplicates(['ID','MJD'], keep='first')\n",
    "# Add observation count to every transient\n",
    "df_count = df_tra.groupby('ID', as_index=False).count()\n",
    "df_count['ObsCount'] = df_count['Mag']\n",
    "df_count = df_count[['ID', 'ObsCount']]\n",
    "df_tra = df_tra.merge(df_count, how='inner')\n",
    "# Remove objects with less than min_obs\n",
    "df_tra_5 = df_tra[df_tra.ObsCount >= 5]\n",
    "df_tra_10 = df_tra[df_tra.ObsCount >= 10]\n",
    "df_tra_5.shape, df_tra_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tra_5.ID.unique().shape[0], df_tra_10.ID.unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import non-transient light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'nontransient_lightcurves.pickle'\n",
    "indir = LIGHTCURVES_PATH; filepath = indir + filename\n",
    "df_nont = pd.read_pickle(filepath)\n",
    "df_nont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nont.ID.unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter non-transient lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows of blended observations\n",
    "df_nont = df_nont.drop_duplicates(['ID','MJD'], keep='first')\n",
    "# Add observation count to every nontransient\n",
    "df_count = df_nont.groupby('ID', as_index=False).count()\n",
    "df_count['ObsCount'] = df_count['Mag']\n",
    "df_count = df_count[['ID', 'ObsCount']]\n",
    "df_nont = df_nont.merge(df_count, how='inner')\n",
    "# Remove nontransient objects with less than 5 observations\n",
    "df_nont_5 = df_nont[df_nont.ObsCount >= 5]\n",
    "# Remove nontransient objects with less than 10 observations\n",
    "df_nont_10 = df_nont[df_nont.ObsCount >= 10]\n",
    "df_nont_5.shape, df_nont_10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversample/balance transient light curves using error as gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(df, copies=0):\n",
    "    df_oversample = df.copy()\n",
    "    df_oversample['CopyID'] = '0-' + df_oversample['ID']\n",
    "    for i in range(1, copies+1):\n",
    "        df_temp = df.copy()\n",
    "        df_temp['CopyID'] = '{}-'.format(i) + df_temp['ID']\n",
    "        df_temp['Mag'] = np.random.normal(df.Mag, df.Magerr)\n",
    "        df_oversample = df_oversample.append(df_temp, ignore_index=True)\n",
    "    return df_oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample Data Frames\n",
    "df_tra_5 = oversample(df_tra_5, 6)\n",
    "df_tra_10 = oversample(df_tra_10, 6)\n",
    "df_nont_5 = oversample(df_nont_5, 0)\n",
    "df_nont_10 = oversample(df_nont_10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tra_5.CopyID.unique().shape, df_tra_10.CopyID.unique().shape, df_nont_5.CopyID.unique().shape, df_nont_10.CopyID.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df_all):\n",
    "    # Create empty feature dict\n",
    "    feats_dict = extract.feature_dict(31)\n",
    "    copyIDs = []\n",
    "    for i, copyID in enumerate(df_all.CopyID.unique()):\n",
    "        if(i%1000 == 0): print(i)\n",
    "        # Get current object light curve\n",
    "        df = df_all[df_all.CopyID == copyID]\n",
    "        # Get features\n",
    "        obj_feats = extract.features(df, feats_dict)\n",
    "        # Append features\n",
    "        for k,v in feats_dict.items():\n",
    "            if k != 'ID': feats_dict[k].append(obj_feats[k])\n",
    "        feats_dict['ID'].append(df.ID.iloc[0])\n",
    "        copyIDs.append(copyID)\n",
    "    # Create feature dataframe\n",
    "    feats_dict['CopyID'] = copyIDs \n",
    "    return pd.DataFrame(feats_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save features routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(df_feats, min_obs, tipe):\n",
    "#    print(df_feats.count())\n",
    "#    print(df_feats.T.apply(lambda x: x.nunique(), axis=1))\n",
    "    outdir = FEATURES_PATH\n",
    "    filename_form = 'oversam_{}_{}obs_{}feats.pickle'\n",
    "    # Save all 31 features\n",
    "    num_features = df_feats.shape[1]-2\n",
    "    filename = filename_form.format(tipe, min_obs, num_features) \n",
    "    df_feats.to_pickle(outdir + filename)\n",
    "    # Save all 27 features\n",
    "    df_feats = df_feats.drop(['poly4_a', 'poly4_b', 'poly4_c', 'poly4_d'], axis=1)\n",
    "    num_features = df_feats.shape[1]-2\n",
    "    filename = filename_form.format(tipe, min_obs, num_features) \n",
    "    df_feats.to_pickle(outdir + filename)\n",
    "    # Save all 21 features\n",
    "    df_feats = df_feats.drop(['poly1_a','poly2_a','poly2_b','poly3_a','poly3_b','poly3_c'], axis=1)\n",
    "    num_features = df_feats.shape[1]-2\n",
    "    filename = filename_form.format(tipe, min_obs, num_features) \n",
    "    df_feats.to_pickle(outdir + filename)\n",
    "    # Save all 19 features\n",
    "    df_feats = df_feats.drop(['small_kurtosis','pair_slope_trend_last_30'], axis=1)\n",
    "    num_features = df_feats.shape[1]-2\n",
    "    filename = filename_form.format(tipe, min_obs, num_features) \n",
    "    df_feats.to_pickle(outdir + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate features routine by extracting and saving them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df_all, min_obs, transient):\n",
    "    df_feats = extract_features(df_all)\n",
    "    save_features(df_feats, min_obs, 'transient' if transient else 'nontransient')\n",
    "    print('Finished task obs={} transient={}'.format(min_obs, transient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_features(df_nont_10, 10, False )\n",
    "generate_features(df_tra_10, 10, True)\n",
    "generate_features(df_nont_5, 5, False )\n",
    "generate_features(df_tra_5, 5, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
