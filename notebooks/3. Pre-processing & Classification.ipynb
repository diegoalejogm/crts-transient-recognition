{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = '../results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import inputs\n",
    "import classification\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the parameters and models for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = [inputs.binary]#[inputs.binary, inputs.six_transient, inputs.seven_transient, inputs.seven_class, inputs.eight_class]\n",
    "min_obs_list = [10]\n",
    "num_features_list = [30]\n",
    "oversample_list = [True]\n",
    "model_list = [classification.rf]#classification.svc, classification.rf, classification.mlp]\n",
    "scaler_list = [StandardScaler]#, MinMaxScaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_list = [inputs.binary, inputs.six_transient, inputs.seven_transient, inputs.seven_class, inputs.eight_class]\n",
    "# min_obs_list = [5,10]\n",
    "# num_features_list = [30, 26, 20]\n",
    "# oversample_list = [True, False]\n",
    "# model_list = [classification.svc, classification.rf, classification.mlp]\n",
    "# scaler_list = [StandardScaler, MinMaxScaler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every combination of parameters selected, perform pre-processing and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combination_results_dict(min_obs, num_features, oversample, model_name, scaler_name, best_score, best_params):\n",
    "    combination_results = {}\n",
    "    combination_results['min_obs'] = min_obs\n",
    "    combination_results['num_features'] = num_features\n",
    "    combination_results['oversample'] = oversample\n",
    "    combination_results['model'] = model_name\n",
    "    combination_results['scaler'] = scaler_name\n",
    "    combination_results['best_score']  = best_score\n",
    "    combination_results['best_params'] = best_params\n",
    "    return combination_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TASK:  binary 10 30 True rf StandardScaler\n",
      "[[  1.12135      0.30769231   0.06736346   0.14507436   0.15970023\n",
      "    0.29611975   0.51916946  -0.55294691   7.12407381   0.54422249\n",
      "    0.07692308   0.46153846   0.2         21.04956368  12.48804478\n",
      "    0.32114705  -4.46691107   4.94277932   3.78776031  -9.86318526\n",
      "    6.81205335 -21.78511289  47.63374    -37.46448387  12.34726829\n",
      "   -0.28759767  -3.92727273   0.6814712   -0.56282221   0.70797157]]\n",
      "[[ 1.00000000e-01  3.61111111e-01  9.48667925e-02  2.38112247e-01\n",
      "   3.13897330e-01  5.43428216e-01  6.99187232e-01  2.13463856e-01\n",
      "   7.81738587e-01  2.97205075e-02  7.40740741e-01  4.44444444e-01\n",
      "   4.33333333e-01  2.58925412e-01  1.13079364e-01 -4.16497732e-02\n",
      "   7.23910155e-03 -4.91592955e-02  1.70182451e-02 -1.91722911e-02\n",
      "  -3.84444639e-02 -9.13971379e-01  1.84676984e+00 -1.17428879e+00\n",
      "   2.02709401e-01  1.35691819e-01 -3.08598383e+00  3.83660522e-02\n",
      "   6.63615272e-02  7.79695561e-01]\n",
      " [ 1.63500000e+00  2.00000000e-01  1.01162511e-01  1.85269351e-01\n",
      "   3.18540246e-01  5.01673730e-01  8.87512633e-01  5.57944719e+00\n",
      "   8.20802005e+00  3.46212346e-01  8.88888889e-02  5.33333333e-01\n",
      "   5.66666667e-01  1.30825674e+02  2.68190861e+00  5.71068828e-02\n",
      "  -7.71183770e-01  8.24594670e-01  6.11551165e-01 -1.63055392e+00\n",
      "   1.10226776e+00  1.51177412e+01 -3.04760055e+01  1.82970395e+01\n",
      "  -2.80151192e+00 -1.11746064e+00 -3.21594684e+00  5.19689398e-01\n",
      "  -7.67921679e-02  5.03813433e-01]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Buffer dtype mismatch, expected 'Python object' but got 'double'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-233-92bce0e96822>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Obtain inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         X_train, X_test, y_train, y_test = task(min_obs, num_features,\n\u001b[0;32m---> 14\u001b[0;31m                                                 oversample=oversample)\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Scale inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfit_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/astro/repo/notebooks/inputs.py\u001b[0m in \u001b[0;36mbinary\u001b[0;34m(min_obs, num_features, remove_ids, oversample)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# Load feature dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mdf_feat_tran\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_transient_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mdf_feat_nont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_nontransient_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/astro/repo/notebooks/inputs.py\u001b[0m in \u001b[0;36mload_transient_features\u001b[0;34m(min_obs, num_features, oversample)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtask_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mdf_feat_tran\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__filter_oversampled_transient__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_feat_tran\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_feat_tran\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/astro/repo/notebooks/inputs.py\u001b[0m in \u001b[0;36m__filter_oversampled_transient__\u001b[0;34m(df_all, task, min_obs, num_features)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# Remove testing data from df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mdf_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;31m#    print('df_task', df_task.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;31m# Count number of objects per class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.0/lib/python3.5/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(self, values, level)\u001b[0m\n\u001b[1;32m   2768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m             values = MultiIndex.from_tuples(values,\n\u001b[0;32m-> 2770\u001b[0;31m                                             names=self.names).values\n\u001b[0m\u001b[1;32m   2771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.0/lib/python3.5/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mfrom_tuples\u001b[0;34m(cls, tuples, sortorder, names)\u001b[0m\n\u001b[1;32m   1193\u001b[0m                 \u001b[0mtuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuples_to_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_object_array_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.tuples_to_object_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'Python object' but got 'double'"
     ]
    }
   ],
   "source": [
    "combinations = itertools.product(\n",
    "    min_obs_list, num_features_list, oversample_list, model_list, scaler_list\n",
    ")\n",
    "for task in task_list:\n",
    "    results_task = list()\n",
    "    results_models = list()\n",
    "    for combination in combinations:\n",
    "        \n",
    "        min_obs, num_features, oversample, model, scaler = combination      \n",
    "        print('STARTING TASK: ', task.__name__, min_obs, num_features, oversample, model.__name__, scaler.__name__)\n",
    "\n",
    "        # Obtain inputs\n",
    "        X_train, X_test, y_train, y_test = task(min_obs, num_features,\n",
    "                                                oversample=oversample)\n",
    "        # Scale inputs\n",
    "        fit_scaler = scaler().fit(X_train)\n",
    "        X_train = fit_scaler.transform(X_train); X_test = fit_scaler.transform(X_test)\n",
    "        # Perform Classification\n",
    "        clf = model(X_train, y_train, X_test, y_test, \n",
    "                    min_obs, num_features, oversample, task, fit_scaler)\n",
    "    \n",
    "        # Store temporary results\n",
    "        results_models.append(clf.best_estimator_)\n",
    "        \n",
    "        combination_results = combination_results_dict(\n",
    "            min_obs, num_features, oversample, model.__name__,\n",
    "            scaler.__name__, clf.best_score_,clf.best_params_\n",
    "        )\n",
    "        results_task.append(combination_results)\n",
    "        \n",
    "    # Generate DataFrame with current task's results\n",
    "    df_results_task = pd.DataFrame(results_task)\n",
    "    df_results_task.to_pickle(RESULTS_PATH + 'dataframes/{}.pkl'.format(task.__name__))\n",
    "    \n",
    "    # Find and Save best model\n",
    "    task_best_index = df_results_task['best_score'].idxmax()\n",
    "    task_best_model = results_models[task_best_index]\n",
    "    joblib.dump(task_best_model, RESULTS_PATH + 'models/{}.pkl'.format(task.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "      <th>min_obs</th>\n",
       "      <th>model</th>\n",
       "      <th>num_features</th>\n",
       "      <th>oversample</th>\n",
       "      <th>scaler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "      <td>0.742822</td>\n",
       "      <td>10</td>\n",
       "      <td>rf</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>StandardScaler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     best_params  best_score  min_obs model  \\\n",
       "0  {'max_features': 'auto', 'n_estimators': 200}    0.742822       10    rf   \n",
       "\n",
       "   num_features  oversample          scaler  \n",
       "0            30       False  StandardScaler  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
