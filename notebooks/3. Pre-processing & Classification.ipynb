{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = '../results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import inputs\n",
    "import classification\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the parameters and models for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_list = [inputs.binary, inputs.six_transient, inputs.seven_transient, inputs.seven_class, inputs.eight_class]\n",
    "# min_obs_list = [5,10]\n",
    "# num_features_list = [31, 27, 21]\n",
    "# oversample_list = [True, False]\n",
    "# model_list = [classification.svc, classification.rf, classification.mlp]\n",
    "# scaler_list = [StandardScaler, MinMaxScaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = [inputs.eight_class]\n",
    "min_obs_list = [10]\n",
    "num_features_list = [27]\n",
    "oversample_list = [False]\n",
    "model_list = [classification.rf]\n",
    "scaler_list = [StandardScaler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every combination of parameters selected, perform pre-processing and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TASK:  eight_class 10 27 False rf StandardScaler\n",
      "Train Shapes (X, y):  (3200, 27), (3200,)\n",
      "Test Shapes (X, y):  (1577, 27), (1577,)\n",
      "Unique classes: ['AGN' 'Blazar' 'CV' 'Flare' 'HPM' 'Non-Transient' 'Other' 'SN']\n",
      "Unique count: [285 156 524 125 268 703 436 703]\n",
      "Best Params: {'max_features': 'auto', 'n_estimators': 700}\n",
      "Validation Accuracy: 0.6609\n",
      "Test Accuracy: 0.6823\n",
      "Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          AGN     0.7153    0.7305    0.7228       141\n",
      "       Blazar     0.6667    0.3421    0.4522        76\n",
      "           CV     0.7636    0.7636    0.7636       258\n",
      "        Flare     0.6571    0.3710    0.4742        62\n",
      "          HPM     0.9291    0.8939    0.9112       132\n",
      "Non-Transient     0.6725    0.8934    0.7673       347\n",
      "        Other     0.4800    0.3364    0.3956       214\n",
      "           SN     0.6253    0.6542    0.6394       347\n",
      "\n",
      "  avg / total     0.6753    0.6823    0.6695      1577\n",
      "Confusion Matrix:\n",
      " [[103   4   1   0   0   9  20   4]\n",
      " [  9  26  13   0   0   0  10  18]\n",
      " [  1   5 197   1   2   4  12  36]\n",
      " [  1   0   3  23   0  26   1   8]\n",
      " [  1   0   0   1 118  12   0   0]\n",
      " [  1   0   3   5   3 310  12  13]\n",
      " [ 27   4  18   2   2  32  72  57]\n",
      " [  1   0  23   3   2  68  23 227]]\n",
      "Normalized Confusion Matrix:\n",
      " [[ 73.05   2.84   0.71   0.     0.     6.38  14.18   2.84]\n",
      " [ 11.84  34.21  17.11   0.     0.     0.    13.16  23.68]\n",
      " [  0.39   1.94  76.36   0.39   0.78   1.55   4.65  13.95]\n",
      " [  1.61   0.     4.84  37.1    0.    41.94   1.61  12.9 ]\n",
      " [  0.76   0.     0.     0.76  89.39   9.09   0.     0.  ]\n",
      " [  0.29   0.     0.86   1.44   0.86  89.34   3.46   3.75]\n",
      " [ 12.62   1.87   8.41   0.93   0.93  14.95  33.64  26.64]\n",
      " [  0.29   0.     6.63   0.86   0.58  19.6    6.63  65.42]]\n",
      "Finished Task\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for combination in itertools.product(task_list, min_obs_list, num_features_list, oversample_list, model_list, scaler_list):\n",
    "    task, min_obs, num_features, oversample, model, scaler = combination\n",
    "    print('STARTING TASK: ', task.__name__, min_obs, num_features, oversample, model.__name__, scaler.__name__)\n",
    "    # Obtain inputs\n",
    "    X_train, X_test, y_train, y_test = task(min_obs, num_features, oversample=oversample)\n",
    "    # Scale inputs\n",
    "    scaler = scaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    # Perform Classification\n",
    "    clf = model(X_train, y_train, X_test, y_test, min_obs, num_features, oversample, task, scaler)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    ID_test = task(min_obs, num_features, oversample=oversample, remove_ids=False)[1][:,0]\n",
    "    incorrect = np.where(y_pred != y_test)\n",
    "    correct = np.where(y_pred == y_test)\n",
    "    print('Finished Task\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objects = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain Correctly classified objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGN\n",
      "['TranID1511190090264135161', 'TranID1602271320384111174', 'TranID1104010150534111525', 'TranID1105061460454102381']\n",
      "Blazar\n",
      "['TranID1511081150254112077', 'TranID1109180041254129754', 'TranID1006040091104115912', 'TranID1009151090134116882']\n",
      "CV\n",
      "['TranID1004121380694101469', 'TranID809221210074124820', 'TranID1004080180844150528', 'TranID1201191570254149183']\n",
      "Flare\n",
      "['TranID812020070254115621', 'TranID1105261210664103986', 'TranID1607041211134127847', 'TranID1301141010054127807']\n",
      "HPM\n",
      "['TranID1511081570324139313', 'TranID1506191071194103098', 'TranID1607061380624103568', 'TranID1504011460534132127']\n",
      "Non-Transient\n",
      "['CataID2103025023457', 'CataID2008186028039', 'CataID1015107048794', 'CataID1121020060511']\n",
      "Other\n",
      "['TranID1306201260664112997', 'TranID1004100040684115432', 'TranID1212051210064142482', 'TranID1103091230694138108']\n",
      "SN\n",
      "['TranID1212071120514101732', 'TranID1102231350604110103', 'TranID901021180674115321', 'TranID1610051290094112842']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "dict_correct = { 'task': task.__name__ }\n",
    "\n",
    "for target in np.unique(y_pred):\n",
    "    correct_target_indexes = np.where(y_pred[correct] == target)[0]\n",
    "    num_target_objects = correct_target_indexes.shape[0]\n",
    "    rand_indexes = np.random.choice(num_target_objects, num_objects, replace=False)\n",
    "    dict_correct[target] = ID_test[correct][correct_target_indexes][rand_indexes].tolist()\n",
    "    print(target)\n",
    "    print(dict_correct[target])\n",
    "with open('correct.txt','w') as f:\n",
    "    f.write(str(dict_correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain incorrectly classified objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGN\n",
      "['TranID1202011430404119121', 'TranID1503131380534110321', 'TranID1212201070564109636', 'TranID1304151460494144378']\n",
      "Blazar\n",
      "['TranID1309161261134112078', 'TranID1004060010564103401', 'TranID1001150010144126826', 'TranID905171230654131642']\n",
      "CV\n",
      "['TranID1411180090094108372', 'TranID904031350204105547', 'TranID1605310070594119120', 'TranID909111210064128226']\n",
      "Flare\n",
      "['TranID1512161181174138560', 'TranID1012061010234104635', 'TranID1610211260104103466', 'TranID1505241120834142545']\n",
      "HPM\n",
      "['TranID1111031520324144272', 'TranID1504211350674136634', 'TranID1610241600204126524', 'TranID1204011230584135800']\n",
      "Non-Transient\n",
      "['CataID1138012047066', 'CataID1115057015149', 'CataID2116014019996', 'CataID1007113019532']\n",
      "Other\n",
      "['TranID1111230010184112537', 'TranID1303171290584119068', 'TranID1510121400034160762', 'TranID1503261490484103204']\n",
      "SN\n",
      "['TranID804011150764118274', 'TranID1510161150164123038', 'TranID1104131150874170907', 'TranID1010101351004150592']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "dict_incorrect = { 'task': task.__name__ }\n",
    "\n",
    "for target in np.unique(y_pred):\n",
    "    incorrect_target_indexes = (np.where(y_test[incorrect] == target))[0]\n",
    "    num_target_objects = incorrect_target_indexes.shape[0]\n",
    "    rand_indexes = np.random.choice(num_target_objects, num_objects, replace=False)\n",
    "    dict_incorrect[target] = ID_test[incorrect][incorrect_target_indexes][rand_indexes].tolist()\n",
    "    print(target)\n",
    "    print(dict_incorrect[target])\n",
    "with open('incorrect.txt','w') as f:\n",
    "    f.write(str(dict_incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ID_test[correct][:15], y_test[correct][:15], y_pred[correct][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ID_test[incorrect][:15], y_test[incorrect][:15], y_pred[incorrect][:15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
